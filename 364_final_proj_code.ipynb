{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303b3e8",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f109da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ee3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(\"valid.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])\n",
    "train_df = pd.read_csv(\"train.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])\n",
    "test_df = pd.read_csv(\"test.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])\n",
    "noisy_df = pd.read_csv(\"unlabeled_test_with_noise.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a353c031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>Text</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1241490299215634434</td>\n",
       "      <td>Official death toll from #covid19 in the Unite...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245916400981381130</td>\n",
       "      <td>Dearest Mr. President @USER 1,169 coronavirus ...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1241132432402849793</td>\n",
       "      <td>Latest Updates March 20 锔5274 new cases and 3...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1236107253666607104</td>\n",
       "      <td>涓讳褰骞查 BREAKING: 21 people on Grand Princess...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>1241325232415105025</td>\n",
       "      <td>.@USER makes major announcement in view of #co...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6933</th>\n",
       "      <td>1235624084089778176</td>\n",
       "      <td>QUESTION ... did they receive a Ventilator wh...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>1246018213995044870</td>\n",
       "      <td>CMT will air a special celebrating the life&amp;am...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>1239750367329439744</td>\n",
       "      <td>Current  COVID19 testing procedure only test...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>1241528434624327680</td>\n",
       "      <td>A preview of whats to come, the further the s...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6937 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id                                               Text  \\\n",
       "0                      Id                                               Text   \n",
       "1     1241490299215634434  Official death toll from #covid19 in the Unite...   \n",
       "2     1245916400981381130  Dearest Mr. President @USER 1,169 coronavirus ...   \n",
       "3     1241132432402849793  Latest Updates March 20 锔5274 new cases and 3...   \n",
       "4     1236107253666607104  涓讳褰骞查 BREAKING: 21 people on Grand Princess...   \n",
       "...                   ...                                                ...   \n",
       "6932  1241325232415105025  .@USER makes major announcement in view of #co...   \n",
       "6933  1235624084089778176  QUESTION ... did they receive a Ventilator wh...   \n",
       "6934  1246018213995044870  CMT will air a special celebrating the life&am...   \n",
       "6935  1239750367329439744  Current  COVID19 testing procedure only test...   \n",
       "6936  1241528434624327680  A preview of whats to come, the further the s...   \n",
       "\n",
       "              Label  \n",
       "0             Label  \n",
       "1       INFORMATIVE  \n",
       "2       INFORMATIVE  \n",
       "3       INFORMATIVE  \n",
       "4       INFORMATIVE  \n",
       "...             ...  \n",
       "6932  UNINFORMATIVE  \n",
       "6933    INFORMATIVE  \n",
       "6934  UNINFORMATIVE  \n",
       "6935  UNINFORMATIVE  \n",
       "6936  UNINFORMATIVE  \n",
       "\n",
       "[6937 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e75b3",
   "metadata": {},
   "source": [
    "# Some data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8564d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the string label to binary values of 0 and 1\n",
    "label_mapping = {\"UNINFORMATIVE\": 0, \"INFORMATIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eebdfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the label mapping to all the datasets\n",
    "valid_df[\"Label\"] = valid_df[\"Label\"].map(label_mapping)\n",
    "noisy_df[\"Label\"] = noisy_df[\"Label\"].map(label_mapping)\n",
    "train_df[\"Label\"] = train_df[\"Label\"].map(label_mapping)\n",
    "test_df[\"Label\"] = test_df[\"Label\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922c2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "  \"\"\"\n",
    "  Simple tokenizer that lowercases and splits on whitespace.\n",
    "  \"\"\"\n",
    "  return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae29ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq=1):\n",
    "  \"\"\"\n",
    "  Build vocabulary on a list/series of text\n",
    "  This allows us to convert text into a series of numbers\n",
    "  This is an easier data that can be read by the model for patterns\n",
    "  \"\"\"\n",
    "  vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "  word_counts = {}\n",
    "  for text in texts:\n",
    "      tokens = simple_tokenizer(text)\n",
    "      for token in tokens:\n",
    "          word_counts[token] = word_counts.get(token, 0) + 1\n",
    "  for token, count in word_counts.items():\n",
    "      if count >= min_freq and token not in vocab:\n",
    "          vocab[token] = len(vocab)\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ca3336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 't': 2,\n",
       " 'h': 3,\n",
       " 'e': 4,\n",
       " 'c': 5,\n",
       " 'a': 6,\n",
       " 's': 7,\n",
       " 'o': 8,\n",
       " 'n': 9,\n",
       " 'f': 10,\n",
       " 'i': 11}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"The cat sat on a cat that sat on the fish\"\n",
    "example_usage = build_vocab(example_text)\n",
    "example_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997c7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary based on training texts\n",
    "vocab = build_vocab(train_df[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa2c64",
   "metadata": {},
   "source": [
    "# Create the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86547d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere we need a dataset class and a dataloader to load the data in batches.\\nThis we see often times in our homework assignments.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we need a dataset class and a dataloader to load the data in batches.\n",
    "This we see often times in our homework assignments.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
