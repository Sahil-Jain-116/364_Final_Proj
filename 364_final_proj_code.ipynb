{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303b3e8",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f109da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ee3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(\"valid.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])\n",
    "train_df = pd.read_csv(\"train.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])\n",
    "test_df = pd.read_csv(\"test.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])\n",
    "noisy_df = pd.read_csv(\"unlabeled_test_with_noise.tsv\", sep='\\t', names=[\"Id\", \"Text\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a353c031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>Text</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1241490299215634434</td>\n",
       "      <td>Official death toll from #covid19 in the Unite...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245916400981381130</td>\n",
       "      <td>Dearest Mr. President @USER 1,169 coronavirus ...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1241132432402849793</td>\n",
       "      <td>Latest Updates March 20 ⚠️5274 new cases and 3...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1236107253666607104</td>\n",
       "      <td>真把公主不当干部 BREAKING: 21 people on Grand Princess...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>1241325232415105025</td>\n",
       "      <td>.@USER makes major announcement in view of #co...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6933</th>\n",
       "      <td>1235624084089778176</td>\n",
       "      <td>❌QUESTION ... did they receive a Ventilator wh...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>1246018213995044870</td>\n",
       "      <td>CMT will air a special celebrating the life&amp;am...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>1239750367329439744</td>\n",
       "      <td>Current 🇮🇩 COVID19 testing procedure only test...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>1241528434624327680</td>\n",
       "      <td>A preview of what’s to come, the further the s...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6937 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id                                               Text  \\\n",
       "0                      Id                                               Text   \n",
       "1     1241490299215634434  Official death toll from #covid19 in the Unite...   \n",
       "2     1245916400981381130  Dearest Mr. President @USER 1,169 coronavirus ...   \n",
       "3     1241132432402849793  Latest Updates March 20 ⚠️5274 new cases and 3...   \n",
       "4     1236107253666607104  真把公主不当干部 BREAKING: 21 people on Grand Princess...   \n",
       "...                   ...                                                ...   \n",
       "6932  1241325232415105025  .@USER makes major announcement in view of #co...   \n",
       "6933  1235624084089778176  ❌QUESTION ... did they receive a Ventilator wh...   \n",
       "6934  1246018213995044870  CMT will air a special celebrating the life&am...   \n",
       "6935  1239750367329439744  Current 🇮🇩 COVID19 testing procedure only test...   \n",
       "6936  1241528434624327680  A preview of what’s to come, the further the s...   \n",
       "\n",
       "              Label  \n",
       "0             Label  \n",
       "1       INFORMATIVE  \n",
       "2       INFORMATIVE  \n",
       "3       INFORMATIVE  \n",
       "4       INFORMATIVE  \n",
       "...             ...  \n",
       "6932  UNINFORMATIVE  \n",
       "6933    INFORMATIVE  \n",
       "6934  UNINFORMATIVE  \n",
       "6935  UNINFORMATIVE  \n",
       "6936  UNINFORMATIVE  \n",
       "\n",
       "[6937 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e75b3",
   "metadata": {},
   "source": [
    "# Some data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8564d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the string label to binary values of 0 and 1\n",
    "label_mapping = {\"UNINFORMATIVE\": 0, \"INFORMATIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eebdfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the label mapping to all the datasets\n",
    "valid_df[\"Label\"] = valid_df[\"Label\"].map(label_mapping)\n",
    "noisy_df[\"Label\"] = noisy_df[\"Label\"].map(label_mapping)\n",
    "train_df[\"Label\"] = train_df[\"Label\"].map(label_mapping)\n",
    "test_df[\"Label\"] = test_df[\"Label\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922c2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "  \"\"\"\n",
    "  Simple tokenizer that lowercases and splits on whitespace.\n",
    "  \"\"\"\n",
    "  return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae29ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq=1):\n",
    "  \"\"\"\n",
    "  Build vocabulary on a list/series of text\n",
    "  This allows us to convert text into a series of numbers\n",
    "  This is an easier data that can be read by the model for patterns\n",
    "  \"\"\"\n",
    "  vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "  word_counts = {}\n",
    "  for text in texts:\n",
    "      tokens = simple_tokenizer(text)\n",
    "      for token in tokens:\n",
    "          word_counts[token] = word_counts.get(token, 0) + 1\n",
    "  for token, count in word_counts.items():\n",
    "      if count >= min_freq and token not in vocab:\n",
    "          vocab[token] = len(vocab)\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ca3336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 't': 2,\n",
       " 'h': 3,\n",
       " 'e': 4,\n",
       " 'c': 5,\n",
       " 'a': 6,\n",
       " 's': 7,\n",
       " 'o': 8,\n",
       " 'n': 9,\n",
       " 'f': 10,\n",
       " 'i': 11}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"The cat sat on a cat that sat on the fish\"\n",
    "example_usage = build_vocab(example_text)\n",
    "example_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997c7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary based on training texts\n",
    "vocab = build_vocab(train_df[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa2c64",
   "metadata": {},
   "source": [
    "# Create the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86547d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere we need a dataset class and a dataloader to load the data in batches.\\nThis we see often times in our homework assignments.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we need a dataset class and a dataloader to load the data in batches.\n",
    "This we see often times in our homework assignments.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
